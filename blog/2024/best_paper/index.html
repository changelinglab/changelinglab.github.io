<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> On our ACL Best Paper Award Paper | ChangeLing Lab </title> <meta name="author" content="ChangeLing Lab"> <meta name="description" content="a short philosophical discursion"> <meta name="keywords" content="linguistics, computational-linguistics, natural-language-processing, diachronic, phonology, morphology, sociolinguistics"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%CA%A7&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://changelinglab.github.io/blog/2024/best_paper/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">ChangeLing</span> Lab </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">On our ACL Best Paper Award Paper</h1> <p class="post-meta"> Created in August 15, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/formatting"> <i class="fa-solid fa-hashtag fa-sm"></i> formatting</a>   <a href="/blog/tag/links"> <i class="fa-solid fa-hashtag fa-sm"></i> links</a>   ·   <a href="/blog/category/sample-posts"> <i class="fa-solid fa-tag fa-sm"></i> sample-posts</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Yesterday, my student Liang (Leon) Lu won the Best Paper Award (Non-Publicized) at the 2024 Association for Computational Linguistics conference in Bangkok for his paper “Semisupervised Neural Proto-Language Reconstruction.” We are generally impressed by students who win this awards, but in Leon’s case their is double reason to be impressed. Not only is he an undergraduate student (just starting his third year of university), he has only submitted two papers to conferences. Both were accepted and the second (his first submission to a *ACL conference) was the subject of this best paper award. But what is the substance of this paper?</p> <p>If you are technical, you can go and read the paper for yourself. It is short and is, I think, fairly clearly written. If you are not technical but you have some training in historical linguistics, you will recognize some of the principal themes, even if you don’t follow the complete methodology or analysis. However, if you are neither technical nor trained in historical linguistics, but you still want to know what this paper was about, I will do me best to let you know.</p> <p>First, let us consider a table of words from the related languages Kachai, Huishu, and Ukhrul (members of the family of languages called Tangkhulic):</p> <table> <thead> <tr> <th>Gloss</th> <th>‘grandchild’</th> <th>‘bone’</th> <th>‘breast’</th> <th>‘laugh’</th> </tr> </thead> <tbody> <tr> <td>Kachai</td> <td>ðɐ</td> <td>rɐ</td> <td>nɐ</td> <td>ni</td> </tr> <tr> <td>Huishu</td> <td>ruk</td> <td>ruk</td> <td>nuk</td> <td>nuk</td> </tr> <tr> <td>Ukhrul</td> <td>ru</td> <td>ru</td> <td>nu</td> <td>nu</td> </tr> </tbody> </table> <p>Note that the ð sound is like the th in <em>this</em> and the ɐ sound is sort of like the u in cup.</p> <p>If you look at these words, you can see that there is, for example, a systematic relationship between the words for ‘bone‘ and those for ‘breast’. This extends to ‘grandchild’ as well, even though there is a somewhat unexpected consonant in Kachai (ð). What did the ancestors of these words look like in the shared ancestor of these languages? Is this lost in the mists of history?</p> <p>A group of 19th century linguists (of philologists, to use the terminology then current) called the Neogrammarians said you can know how these ancestral forms of words (protoforms) were pronounced by applying a methodology we now call the Comparative Method. Central to this method is the <strong>regularity principle</strong> which states that changes in pronunciation apply as general rules to which <strong>all</strong> words in a language are subject. This means that if you know the protoform for one of the columns in the table (these columns are what are known as “cognate sets”) you can derive all of the rows in that column deterministically—mechanically and unambiguously.</p> <p>Under these Neogrammarian assumptions, we could posit *ruk or *ru as reconstructions for ‘bone’. If we posit *ru, we must assert that there was a sound change in Kachai that changed u to ɐ and a sound change in Huishu that inserted k at the ends of words (perhaps after u). If we reconstruction *ruk, we have to assume that there was a sound change in both Kachai and Ukhrul that deletes k at the end of words (perhaps after u) and another sound change in Kachai that changes u to ɐ. The first option (*ru) ends up working better if we look at all of the cognate sets instead of just these four.</p> <p>By this logic, we get:</p> <table> <thead> <tr> <th>Gloss</th> <th>‘grandchild’</th> <th>‘bone’</th> <th>‘breast’</th> <th>‘laugh’</th> </tr> </thead> <tbody> <tr> <td>Kachai</td> <td>ðɐ</td> <td>rɐ</td> <td>nɐ</td> <td>ni</td> </tr> <tr> <td>Huishu</td> <td>ruk</td> <td>ruk</td> <td>nuk</td> <td>nuk</td> </tr> <tr> <td>Ukhrul</td> <td>ru</td> <td>ru</td> <td>nu</td> <td>nu</td> </tr> </tbody> <tbody> <tr> <td>Proto-Tangkhulic</td> <td>*?u</td> <td>*ru</td> <td>*nu</td> <td>*n?</td> </tr> </tbody> </table> <p>The reconstruction of ‘grandchild’ must end in u, but it must start with something other than r. Why? Because if it did start with r, there would be no way of explaining why, in Kachai, ‘grandchild’ starts with ð but ‘bone’ starts with r through the application of regular sound change. This would be an <strong>unconditioned split</strong>, something that the regularity principle rules out.</p> <p>Looking at the full collection of cognate sets, we would probably make the following reconstructions (or their formal equivalents):</p> <table> <thead> <tr> <th>Gloss</th> <th>‘grandchild’</th> <th>‘bone’</th> <th>‘breast’</th> <th>‘laugh’</th> </tr> </thead> <tbody> <tr> <td>Kachai</td> <td>ðɐ</td> <td>rɐ</td> <td>nɐ</td> <td>ni</td> </tr> <tr> <td>Huishu</td> <td>ruk</td> <td>ruk</td> <td>nuk</td> <td>nuk</td> </tr> <tr> <td>Ukhrul</td> <td>ru</td> <td>ru</td> <td>nu</td> <td>nu</td> </tr> </tbody> <tbody> <tr> <td>Proto-Tangkhulic</td> <td>*du</td> <td>*ru</td> <td>*nu</td> <td>*nɨ</td> </tr> </tbody> </table> <p>where ɨ is a vowel that is half-way between i and u. These protoforms make sense based on the reflexes: they are similar in pronunciation to the reflexes and the reflexes can all be derived from them mechanically.</p> <p>There have been past efforts to build neural models (neural networks) that can perform this kind of reconstruction (including some from our lab), but they have two unfortunate properties:</p> <ol> <li>They only take the reflex-to-protoform mapping into account (not the protoform-to-reflex mapping).</li> <li>Training them (teaching them to generate reconstructions given sets of cognate reflexes) requires many cognate sets, each of which must be paired with a reconstruction.</li> </ol> <p>In actual reconstruction projects, as I know from first hand experience, the constraint in 2 is only satisfied when the most challenging and interesting work in reconstructing a protolanguage has already been done. What Leon discovered as part of this paper is that 2 is a consequence of 1—we are forced to do fully supervised training (a protoform for every cognate set) because we are not enforcing the regularity principle (not rejecting protoforms if—for example—identical protoforms are mapped to different reflex forms in a single language).</p> <p>To make things clearer, let’s return to our example. The older kind of fully-supervised reconstruction models is likely to produce the reconstructions below:</p> <table> <thead> <tr> <th>Gloss</th> <th>‘grandchild’</th> <th>‘bone’</th> <th>‘breast’</th> <th>‘laugh’</th> </tr> </thead> <tbody> <tr> <td>Kachai</td> <td>ðɐ</td> <td>rɐ</td> <td>nɐ</td> <td>ni</td> </tr> <tr> <td>Huishu</td> <td>ruk</td> <td>ruk</td> <td>nuk</td> <td>nuk</td> </tr> <tr> <td>Ukhrul</td> <td>ru</td> <td>ru</td> <td>nu</td> <td>nu</td> </tr> </tbody> <tbody> <tr> <td>Proto-Tangkhulic</td> <td>*du</td> <td>*ru</td> <td>*nu</td> <td><strong>*nu</strong></td> </tr> </tbody> </table> <p>This is because having a u in Ukhrul and a u in Huishu is generally a reliable cue for reconstructing *u in the protoform. However, this reconstruction cannot be right, following the regularity principle, because a single pronunciation in the protolanguage would be reflected as two different pronunciations in Kachai.</p> <p>Leon’s technical innovation was to design a neural network that can learn both to reconstruct protoforms based on reflexes (daughter-to-protoform) and to disfavor protoforms from which reflexes cannot be derived (proto-to-daughter). The D2P and P2D networks are joined together with a “bridge network” that allows both networks to be trained as a single network. The resulting type of neural network is similar in some ways to what is called a “variational autoencoder” but it differs in that the outputs of the D2P network are not real-valued vectors but strings of symbols (in the International Phonetic Alphabet).</p> <p>In training, the model can thus take advantage of cognate sets without a protoform, something that the earlier, fully supervised, models could not do.</p> <p>The implications of this development are striking. Given the same amount of labeled data (cognate sets with protoforms), our DPD models outperform the best fully supervised models as well as the best semisupervised models we could train. And careful statistical testing shows that the differences are as significant as they look at first glance.</p> <p>We think that this approach is very promising and looks forward to a day, not too far in the future, when neural models like this will be a tool in the belt of every historical linguist and will help shed light on the dark recesses of the human past.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/hl_and_information/">Information and Comparative Reconstruction</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/cl_in_acl/">Is ACL an AI (or NLP or CL) Conference?</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/why-diachronic-linguistics/">Why does diachronic linguistics matter?</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ChangeLing Lab. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"David Mortensen's publications including all publications with other members of ChangeLing Lab.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"Ongoing ChangeLing Lab Projects",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-people",title:"people",description:"Members and retroactive alumni of ChangLing Lab",section:"Navigation",handler:()=>{window.location.href="/people/"}},{id:"post-information-and-comparative-reconstruction",title:"Information and Comparative Reconstruction",description:"Informal information-theoretic framing of the comparative method in historical linguistics",section:"Posts",handler:()=>{window.location.href="/blog/2024/hl_and_information/"}},{id:"post-on-our-acl-best-paper-award-paper",title:"On our ACL Best Paper Award Paper",description:"a short philosophical discursion",section:"Posts",handler:()=>{window.location.href="/blog/2024/best_paper/"}},{id:"post-is-acl-an-ai-or-nlp-or-cl-conference",title:"Is ACL an AI (or NLP or CL) Conference?",description:"Ruminations on Emily Bender's Presidential Address at ACL2024",section:"Posts",handler:()=>{window.location.href="/blog/2024/cl_in_acl/"}},{id:"post-why-does-diachronic-linguistics-matter",title:"Why does diachronic linguistics matter?",description:"a short philosophical discursion",section:"Posts",handler:()=>{window.location.href="/blog/2024/why-diachronic-linguistics/"}},{id:"news-sparkles-changeling-lab-is-officially-born-sparkles-though-it-has-long-existed-in-fact",title:'<img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> **ChangeLing Lab is officially born!** <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> (though it has long existed in...',description:"",section:"News"},{id:"news-congratulations-to-liang-leon-lu-for-winning-the-acl2024-best-paper-award-non-publicized-with-his-paper-semisupervised-neural-proto-language-reconstruction-joint-work-with-peirong-xie-and-david-mortensen",title:"Congratulations to Liang (Leon) Lu for winning the ACL2024 Best Paper Award (Non-Publicized)...",description:"",section:"News"},{id:"news-david-mortensen-gave-a-clsp-seminar-at-johns-hopkins-university",title:"David Mortensen gave a CLSP Seminar at Johns Hopkins University.",description:"",section:"News"},{id:"news-congratulations-to-kalvin-chang-and-david-mortensen-for-winning-an-honorable-mention-best-paper-award-at-the-interspeech-2024-responsible-speech-foundation-models-special-session-with-their-paper-quot-self-supervised-speech-representations-still-struggle-with-african-american-vernacular-english-quot-joint-work-with-yi-hui-chou-hsuan-ming-chen-jiatong-shi-nicole-holliday-and-odette-scharenborg",title:"Congratulations to Kalvin Chang and David Mortensen for winning an Honorable Mention, Best...",description:"",section:"News"},{id:"news-our-paper-quot-zero-shot-cross-lingual-ner-using-phonemic-representations-for-low-resource-languages-quot-was-accepted-to-emnlp-2024-main-and-quot-mitigating-the-linguistic-gap-with-phonemic-representations-for-robust-cross-lingual-transfer-quot-was-accepted-to-mrl-2024",title:'Our paper "Zero-Shot Cross-Lingual NER Using Phonemic Representations for Low-Resource Languages" was accepted...',description:"",section:"News"},{id:"news-david-mortensen-will-give-a-talk-as-part-of-the-university-of-pittsburgh-colloquium-series",title:"David Mortensen will give a talk as part of the University of Pittsburgh...",description:"",section:"News"},{id:"news-quot-derivational-morphology-reveals-analogical-generalization-in-large-language-models-quot-leonie-and-david-amp-rsquo-s-collaboration-with-valentin-hofmann-hinrich-sch\xfctze-and-janet-b-pierrehumbert-was-accepted-to-proceedings-of-the-national-academy-of-sciences",title:'"Derivational morphology reveals analogical generalization in large language models" (Leonie and David&rsquo;s collaboration...',description:"",section:"News"},{id:"news-david-gave-a-keynote-on-computational-historical-linguistics-at-midwest-speech-and-language-days-2025",title:"David gave a keynote on computational historical linguistics at Midwest Speech and Language...",description:"",section:"News"},{id:"news-kwanghee-eunjung-kalvin-and-david-amp-rsquo-s-paper-quot-leveraging-allophony-in-self-supervised-speech-models-for-atypical-pronunciation-assessment-quot-was-accepted-to-naacl-2025-main",title:'Kwanghee, Eunjung, Kalvin, and David&rsquo;s paper "Leveraging Allophony in Self-Supervised Speech Models for...',description:"",section:"News"},{id:"news-quot-programming-by-example-meets-historical-linguistics-a-large-language-model-based-approach-to-sound-law-induction-quot-quot-dialup-modeling-the-language-continuum-by-adapting-models-to-dialects-and-dialects-to-models-quot-nate-and-david-39-s-collaboration-with-niyati-bafna-emily-chang-kenton-murray-david-yarowsky-and-hale-sirin-and-quot-zipa-a-family-of-efficient-models-for-multilingual-phone-recognition-quot-collaboration-with-jian-zhu-farhan-samir-eleanor-chodroff-were-accepted-to-acl-2025-main",title:'"Programming by Example meets Historical Linguistics: A Large Language Model Based Approach to...',description:"",section:"News"},{id:"news-kwanghee-nate-and-david-amp-rsquo-s-paper-quot-wav2gloss-generating-interlinear-glossed-text-from-speech-quot-collaboration-with-taiqi-he-lindia-tjuatja-jiatong-shi-shinji-watanabe-graham-neubig-david-mortensen-lori-levin-and-leon-and-david-amp-rsquo-s-paper-quot-semisupervised-neural-proto-language-reconstruction-collaboration-with-peirong-xie-were-accepted-to-acl-2024",title:'Kwanghee, Nate, and David&rsquo;s paper "Wav2Gloss: Generating Interlinear Glossed Text from Speech" (collaboration...',description:"",section:"News"},{id:"news-eunjung-and-david-amp-rsquo-s-journal-paper-quot-applications-of-artificial-intelligence-for-cross-language-intelligibility-assessment-of-dysarthric-speech-quot-was-accepted-to-perspectives-of-the-asha-sig-19",title:'Eunjung and David&rsquo;s journal paper "Applications of Artificial Intelligence for Cross-language Intelligibility Assessment...',description:"",section:"News"},{id:"news-chin-jou-eunjung-kwanghee-and-david-amp-rsquo-s-paper-quot-towards-inclusive-asr-investigating-voice-conversion-for-dysarthric-speech-recognition-in-low-resource-languages-quot-was-accepted-to-interspeech-2025",title:'Chin-jou, Eunjung, Kwanghee, and David&rsquo;s paper "Towards Inclusive ASR: Investigating Voice Conversion for...',description:"",section:"News"},{id:"news-david-mortensen-shinji-watanabe-and-jonathan-amith-have-received-an-nsf-grant-to-leverage-systematic-patterns-among-related-languages-and-dialects-to-improve-asr-for-low-resource-varieties-projects-10-systematic",title:"David Mortensen, Shinji Watanabe, and Jonathan Amith have received an NSF grant to...",description:"",section:"News"},{id:"news-changeling-lab-member-brendon-boldt-will-present-two-papers-in-the-main-session-of-emnlp-2025-in-suzhou-morpheme-induction-for-emergent-language-and-searching-for-the-most-human-like-emergent-language",title:"Changeling Lab member Brendon Boldt will present two papers in the main session...",description:"",section:"News"},{id:"projects-systematic-relationships-for-improved-asr",title:"Systematic Relationships for Improved ASR",description:"Better ASR for low resource varieties",section:"Projects",handler:()=>{window.location.href="/projects/10_systematic/"}},{id:"projects-universal-phone-recognition",title:"Universal Phone Recognition",description:"Recognizing phonetic units in a language-neural fashion",section:"Projects",handler:()=>{window.location.href="/projects/10_universal/"}},{id:"projects-implicit-and-explicit-reasoning-in-llms",title:"Implicit and Explicit Reasoning in LLMs",description:"Do LLMs introspect?",section:"Projects",handler:()=>{window.location.href="/projects/11_blocking/"}},{id:"projects-fbcc-benchmark",title:"FBCC Benchmark",description:"Evaluating the ability of code language models to generalize and plan based on examples",section:"Projects",handler:()=>{window.location.href="/projects/12_benchmark/"}},{id:"projects-automating-comparative-reconstruction",title:"Automating Comparative Reconstruction",description:"Work on developing models that reconstruct protolanguages based on collections of cognate sets",section:"Projects",handler:()=>{window.location.href="/projects/1_automating/"}},{id:"projects-historical-linguistics-as-code-generation",title:"Historical Linguistics as Code Generation",description:"Modeling phonological reconstruction as a code generation problem using LLMs",section:"Projects",handler:()=>{window.location.href="/projects/2_codegen/"}},{id:"projects-emergent-language-corpus-collection",title:"Emergent Language Corpus Collection",description:"Building a collection of corpora from emergent communication systems",section:"Projects",handler:()=>{window.location.href="/projects/3_elcc/"}},{id:"projects-wuggpt",title:"WugGPT",description:"Evaluating the morphological capabilities of Large Language Models",section:"Projects",handler:()=>{window.location.href="/projects/4_wuggpt/"}},{id:"projects-xferbench",title:"XferBench",description:"Evaluating Emergent Communication Systems with Downstream Tasks",section:"Projects",handler:()=>{window.location.href="/projects/5_xferbench/"}},{id:"projects-lexical-change",title:"Lexical Change",description:"Corpus approaches to changes in lexicons",section:"Projects",handler:()=>{window.location.href="/projects/6_lexical_change/"}},{id:"projects-atypical-speech-assessment",title:"Atypical Speech Assessment",description:"Assessing the degree to which speech is atypical",section:"Projects",handler:()=>{window.location.href="/projects/7_evaluating/"}},{id:"projects-phonological-representations-for-nlp",title:"Phonological Representations for NLP",description:"Leveraging phonological representations for NLP tasks",section:"Projects",handler:()=>{window.location.href="/projects/8_phonology_for_nlp/"}},{id:"projects-blocking-in-llms",title:"Blocking in LLMs",description:"Do LLMs know the badness of badity?",section:"Projects",handler:()=>{window.location.href="/projects/9_implicit_explicit/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%64%6D%6F%72%74%65%6E%73@%63%73.%63%6D%75.%65%64%75","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0002-3927-6851","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=2iS5aeoAAAAJ&hl","_blank")}},{id:"socials-semantic-scholar",title:"Semantic Scholar",section:"Socials",handler:()=>{window.open("https://www.semanticscholar.org/author/3407646","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/changelinglab","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/dmort27","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>