<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Automating Comparative Reconstruction | ChangeLing Lab </title> <meta name="author" content="ChangeLing Lab"> <meta name="description" content="Work on developing models that reconstruct protolanguages based on collections of cognate sets"> <meta name="keywords" content="linguistics, computational-linguistics, natural-language-processing, diachronic, phonology, morphology, sociolinguistics"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%CA%A7&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://changelinglab.github.io/projects/1_automating/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">ChangeLing</span> Lab </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Automating Comparative Reconstruction</h1> <p class="post-description">Work on developing models that reconstruct protolanguages based on collections of cognate sets</p> </header> <article> <p>In the 19th century, European philologists made a discovery that would change the direction of the human sciences: they discovered that languages change in systematic ways and that, by leveraging these systematic patterns, it was possible to reproducibly reconstruct ancestors of families of languages (proto-languages) even when no record of those languages survived. This technique, called the comparative method, provided an unprecedented window into the human past—its cultures, its migrations, and its encounters between populations.</p> <p>The assumption that historical changes in pronunciation (“sound changes”) are regular, known as ‘the regularity principle’ or ‘the Neogrammarian hypothesis’, is fundamental to the comparative method. As the 19th century Neogrammarians Hermann Osthoff and Karl Brugmann put it:</p> <blockquote> <p>Every sound change, in so far as it proceeds mechanically, is completed in accordance with laws admitting of no exceptions; i.e. the direction in which the change takes place is always the same for all members of a language community, apart from the case of dialect division, and all words in which the sound subject to change occurs in the same conditions are affected by the change without exception (<em>Morphologische Untersuchungen auf dem Gebiete der indogermanischen Sprachen i</em>).</p> </blockquote> <p>The comparative method, however, is challenging for humans to apply. This is true largely because it involves dealing with large volumes of data and modeling numerous interactions between competing patterns. One must balance the need for phonetic similarity between reconstructed words and their descendants (reflexes) with the need to be able to deterministically derive reflexes from reconstructed words with a single set of sound changes. It imposes a heavy cognitive load. For this reason, researchers have long aspired to implement the comparative method computationally.</p> <p>In this research, we build upon past research in this area.</p> <ul> <li>In <a class="citation" href="#chang2022wikihan">(Chang et al., 2022)</a>, we propose a new resource for Chinese historical phonology (including Middle Chinese and modern Chinese varieties). This data is foundational to our later papers.</li> <li>In <a class="citation" href="#kim2023transformed">(Kim et al., 2023)</a>, we show that Transformer-based models can perform better than RNN (e.g., GRU) based models for supervised protoform reconstruction.</li> <li>In <a class="citation" href="#chang2023automating">(Chang et al., 2023)</a>, we semi-automate intermediate sound change prediction (AISCP) for Tukanoan phylogenetic inference (the process of determining how languages branched off from its relatives). Traditionally, linguists have manually predicted the intermediate stages of sounds that proto-sounds go through, which are then used to group different varieties.</li> <li>In <a class="citation" href="#lu-etal-2024-improved">(Lu et al., 2024)</a>, we further improve automatic comparative reconstruction by using reflex prediction to perform reranking on the beam search results from protoform prediction, emulating the methodology of practicing historical linguists.</li> <li>In <a class="citation" href="#cui2024neuralprotolanguagereconstruction">(Cui et al., 2024)</a>, we explored VAEs for supervised comparative reconstruction.</li> <li>Finally. in <a class="citation" href="#lu2024semisupervisedneuralprotolanguagereconstruction">(Lu et al., 2024)</a>, we showed that it is possible to achieve strong performance on the protoform reconstruction task using only a fraction of the number of labeled data by using the Proto-Daughter-Proto architecture, an end-to-end architecture that favors protoforms that can be derived from cognate sets and from which cognate sets can be derived.</li> </ul> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="lu-etal-2024-improved" class="col-sm-8"> <div class="title">Improved Neural Protoform Reconstruction via Reflex Prediction</div> <div class="author"> Liang Lu, Jingzhi Wang, and David R. Mortensen </div> <div class="periodical"> <em>In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</em>, May 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Protolanguage reconstruction is central to historical linguistics. The comparative method, one of the most influential theoretical and methodological frameworks in the history of the language sciences, allows linguists to infer protoforms (reconstructed ancestral words) from their reflexes (related modern words) based on the assumption of regular sound change. Not surprisingly, numerous computational linguists have attempted to operationalize comparative reconstruction through various computational models, the most successful of which have been supervised encoder-decoder models, which treat the problem of predicting protoforms given sets of reflexes as a sequence-to-sequence problem. We argue that this framework ignores one of the most important aspects of the comparative method: not only should protoforms be inferable from cognate sets (sets of related reflexes) but the reflexes should also be inferable from the protoforms. Leveraging another line of research—reflex prediction—we propose a system in which candidate protoforms from a reconstruction model are reranked by a reflex prediction model. We show that this more complete implementation of the comparative method allows us to surpass state-of-the-art protoform reconstruction methods on three of four Chinese and Romance datasets.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="cui2024neuralprotolanguagereconstruction" class="col-sm-8"> <div class="title">Neural Proto-Language Reconstruction</div> <div class="author"> Chenxuan Cui, Ying Chen, Qinxin Wang, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'David R. Mortensen' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> May 2024 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="lu2024semisupervisedneuralprotolanguagereconstruction" class="col-sm-8"> <div class="title">Semisupervised Neural Proto-Language Reconstruction</div> <div class="author"> Liang Lu, Peirong Xie, and David R. Mortensen </div> <div class="periodical"> May 2024 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="kim2023transformed" class="col-sm-8"> <div class="title">Transformed Protoform Reconstruction</div> <div class="author"> Young Min Kim, Kalvin Chang, Chenxuan Cui, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'David R. Mortensen' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em>, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Protoform reconstruction is the task of inferring what morphemes or words appeared like in the ancestral languages of a set of daughter languages. Meloni et al (2021) achieved the state-of-the-art on Latin protoform reconstruction with an RNN-based encoder-decoder with attention model. We update their model with the state-of-the-art seq2seq model: the Transformer. Our model outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognates spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties. We also probe our model for potential phylogenetic signal contained in the model. Our code is publicly available at \urlhttps://github.com/cmu-llab/acl-2023.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="chang2023automating" class="col-sm-8"> <div class="title">Automating Sound Change Prediction for Phylogenetic Inference: A Tukanoan Case Study</div> <div class="author"> Kalvin Chang, Nathaniel Robinson, Anna Cai, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Ting Chen, Annie Zhang, David Mortensen' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change</em>, Dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>We describe a set of new methods to partially automate linguistic phylogenetic inference given (1) cognate sets with their respective protoforms and sound laws, (2) a mapping from phones to their articulatory features and (3) a typological database of sound changes.We train a neural network on these sound change data to weight articulatory distances between phones and predict intermediate sound change steps between historical protoforms and their modern descendants, replacing a linguistic expert in part of a parsimony-based phylogenetic inference algorithm. In our best experiments on Tukanoan languages, this method produces trees with a Generalized Quartet Distance of 0.12 from a tree that used expert annotations, a significant improvement over other semi-automated baselines. We discuss potential benefits and drawbacks to our neural approach and parsimony-based tree prediction. We also experiment with a minimal generalization learner for automatic sound law induction, finding it less effective than sound laws from expert annotation. Our code is publicly available.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="chang2022wikihan" class="col-sm-8"> <div class="title">WikiHan: A New Comparative Dataset for Chinese Languages</div> <div class="author"> Kalvin Chang, Chenxuan Cui, Youngmin Kim, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'David R. Mortensen' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In COLING 2022</em>, Dec 2022 </div> <div class="periodical"> </div> <div class="links"> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ChangeLing Lab. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"David Mortensen's publications including all publications with other members of ChangeLing Lab.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"Ongoing ChangeLing Lab Projects",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-people",title:"people",description:"Members and retroactive alumni of ChangLing Lab",section:"Navigation",handler:()=>{window.location.href="/people/"}},{id:"post-information-and-comparative-reconstruction",title:"Information and Comparative Reconstruction",description:"Informal information-theoretic framing of the comparative method in historical linguistics",section:"Posts",handler:()=>{window.location.href="/blog/2024/hl_and_information/"}},{id:"post-on-our-acl-best-paper-award-paper",title:"On our ACL Best Paper Award Paper",description:"a short philosophical discursion",section:"Posts",handler:()=>{window.location.href="/blog/2024/best_paper/"}},{id:"post-is-acl-an-ai-or-nlp-or-cl-conference",title:"Is ACL an AI (or NLP or CL) Conference?",description:"Ruminations on Emily Bender's Presidential Address at ACL2024",section:"Posts",handler:()=>{window.location.href="/blog/2024/cl_in_acl/"}},{id:"post-why-does-diachronic-linguistics-matter",title:"Why does diachronic linguistics matter?",description:"a short philosophical discursion",section:"Posts",handler:()=>{window.location.href="/blog/2024/why-diachronic-linguistics/"}},{id:"news-sparkles-changeling-lab-is-officially-born-sparkles-though-it-has-long-existed-in-fact",title:'<img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> ChangeLing Lab is officially born! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> (though it has long existed in...',description:"",section:"News"},{id:"news-congratulations-to-liang-leon-lu-for-winning-the-acl2024-best-paper-award-non-publicized-with-his-paper-self-supervised-neural-protolanguage-reconstruction-joint-work-with-peirong-xie-and-david-mortensen",title:"Congratulations to Liang (Leon) Lu for winning the ACL2024 Best Paper Award (Non-Publicized)...",description:"",section:"News"},{id:"news-david-mortensen-gave-a-clsp-seminar-at-johns-hopkins-university",title:"David Mortensen gave a CLSP Seminar at Johns Hopkins University.",description:"",section:"News"},{id:"news-congratulations-to-kalvin-chang-and-david-mortensen-for-winning-an-honorable-mention-best-paper-award-at-the-interspeech-2024-responsible-speech-foundation-models-special-session-with-their-paper-self-supervised-speech-representations-still-struggle-with-african-american-vernacular-english-joint-work-with-yi-hui-chou-hsuan-ming-chen-jiatong-shi-nicole-holliday-and-odette-scharenborg",title:"Congratulations to Kalvin Chang and David Mortensen for winning an Honorable Mention, Best...",description:"",section:"News"},{id:"news-david-mortensen-will-give-a-talk-as-part-of-the-university-of-pittsburgh-colloquium-series",title:"David Mortensen will give a talk as part of the University of Pittsburgh...",description:"",section:"News"},{id:"projects-systematic-relationships-for-improved-asr",title:"Systematic Relationships for Improved ASR",description:"Better ASR for low resource varieties",section:"Projects",handler:()=>{window.location.href="/projects/10_systematic/"}},{id:"projects-universal-phone-recognition",title:"Universal Phone Recognition",description:"Recognizing phonetic units in a language-neural fashion",section:"Projects",handler:()=>{window.location.href="/projects/10_universal/"}},{id:"projects-implicit-and-explicit-reasoning-in-llms",title:"Implicit and Explicit Reasoning in LLMs",description:"Do LLMs introspect?",section:"Projects",handler:()=>{window.location.href="/projects/11_blocking/"}},{id:"projects-fbcc-benchmark",title:"FBCC Benchmark",description:"Evaluating the ability of code language models to generalize and plan based on examples",section:"Projects",handler:()=>{window.location.href="/projects/12_benchmark/"}},{id:"projects-automating-comparative-reconstruction",title:"Automating Comparative Reconstruction",description:"Work on developing models that reconstruct protolanguages based on collections of cognate sets",section:"Projects",handler:()=>{window.location.href="/projects/1_automating/"}},{id:"projects-historical-linguistics-as-code-generation",title:"Historical Linguistics as Code Generation",description:"Modeling phonological reconstruction as a code generation problem using LLMs",section:"Projects",handler:()=>{window.location.href="/projects/2_codegen/"}},{id:"projects-emergent-language-corpus-collection",title:"Emergent Language Corpus Collection",description:"Building a collection of corpora from emergent communication systems",section:"Projects",handler:()=>{window.location.href="/projects/3_elcc/"}},{id:"projects-wuggpt",title:"WugGPT",description:"Evaluating the morphological capabilities of Large Language Models",section:"Projects",handler:()=>{window.location.href="/projects/4_wuggpt/"}},{id:"projects-xferbench",title:"XferBench",description:"Evaluating Emergent Communication Systems with Downstream Tasks",section:"Projects",handler:()=>{window.location.href="/projects/5_xferbench/"}},{id:"projects-lexical-change",title:"Lexical Change",description:"Corpus approaches to changes in lexicons",section:"Projects",handler:()=>{window.location.href="/projects/6_lexical_change/"}},{id:"projects-atypical-speech-assessment",title:"Atypical Speech Assessment",description:"Assessing the degree to which speech is atypical",section:"Projects",handler:()=>{window.location.href="/projects/7_evaluating/"}},{id:"projects-phonological-representations-for-nlp",title:"Phonological Representations for NLP",description:"Leveraging phonological representations for NLP tasks",section:"Projects",handler:()=>{window.location.href="/projects/8_phonology_for_nlp/"}},{id:"projects-blocking-in-llms",title:"Blocking in LLMs",description:"Do LLMs know the badness of badity?",section:"Projects",handler:()=>{window.location.href="/projects/9_implicit_explicit/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%64%6D%6F%72%74%65%6E%73@%63%73.%63%6D%75.%65%64%75","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0002-3927-6851","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=2iS5aeoAAAAJ&hl","_blank")}},{id:"socials-semantic-scholar",title:"Semantic Scholar",section:"Socials",handler:()=>{window.open("https://www.semanticscholar.org/author/3407646","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/changelinglab","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/dmort27","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>