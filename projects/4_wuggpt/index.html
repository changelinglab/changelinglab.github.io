<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> WugGPT | ChangeLing Lab </title> <meta name="author" content="ChangeLing Lab"> <meta name="description" content="Evaluating the morphological capabilities of Large Language Models"> <meta name="keywords" content="linguistics, computational-linguistics, natural-language-processing, diachronic, phonology, morphology, sociolinguistics"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%CA%A7&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://changelinglab.github.io/projects/4_wuggpt/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">ChangeLing</span> Lab </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">people </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">WugGPT</h1> <p class="post-description">Evaluating the morphological capabilities of Large Language Models</p> </header> <article> <p>Various claims have been made about the linguistic capacities of large language models. Some have asserted that, as next token prediction models, they do not display human-like linguistic “competence.” Others have claimed that the language abilities of LLMs are practically identical to those of humans. One way of testing this is to perform “psycholinguistic” experiments on LLMs.</p> <p>One of the most influential psycholinguistic experiments was the Wug Test, in which small children were asked to complete sentences that required applying a morphological operation to a nonce word (a make-up word). For example, children might be shown a picture of a bird-like creature and be told “this is a wug.” Then, being shown two of the creatures, they would be told, “now there are two of them. There are two….” English speaking children, even very small children, then continue, “wugs!” This test showed that small children are able to generalize morphological and phonological patterns to contexts where they have never seen them before.</p> <p>Our research applies the same technique to language models, investigating the degree to which they can generalize morphology—whether inflection or derivation—to nonce words or, in other words, the degree to which LLMs have human-like morphological behavior.</p> <p>The project, about testing the linguistics capabilities of large language models, has resulted in a couple of papers, with more to come:</p> <ul> <li><a class="citation" href="#weissweiler2023counting">(Weissweiler et al., 2023)</a></li> <li><a class="citation" href="#mortensen-etal-2024-verbing">(Mortensen et al., 2024)</a></li> </ul> <p>In particular, ongoing work compares human and LLM derivational morphology and finds that—like humans—LLMs use analogical relationships to derive words but—unlike humans—current LLMs rely on token frequencies rather than type frequencies of exemplars.</p> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="mortensen-etal-2024-verbing" class="col-sm-8"> <div class="title">Verbing Weirds Language (Models): Evaluation of English Zero-Derivation in Five LLMs</div> <div class="author"> David R. Mortensen, Valentina Izrailevitch, Yunze Xiao, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Hinrich Schütze, Leonie Weissweiler' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</em>, May 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Lexical-syntactic flexibility, in the form of conversion (or zero-derivation) is a hallmark of English morphology. In conversion, a word with one part of speech is placed in a non-prototypical context, where it is coerced to behave as if it had a different part of speech. However, while this process affects a large part of the English lexicon, little work has been done to establish the degree to which language models capture this type of generalization. This paper reports the first study on the behavior of large language models with reference to conversion. We design a task for testing lexical-syntactic flexibility—the degree to which models can generalize over words in a construction with a non-prototypical part of speech. This task is situated within a natural language inference paradigm. We test the abilities of five language models—two proprietary models (GPT-3.5 and GPT-4), three open source model (Mistral 7B, Falcon 40B, and Llama 2 70B). We find that GPT-4 performs best on the task, followed by GPT-3.5, but that the open source language models are also able to perform it and that the 7-billion parameter Mistral displays as little difference between its baseline performance on the natural language inference task and the non-prototypical syntactic category task, as the massive GPT-4.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="weissweiler2023counting" class="col-sm-8"> <div class="title">Counting the Bugs in ChatGPT’s Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model</div> <div class="author"> Leonie Weissweiler, Valentin Hofmann, Anjali Kantharuban, and <span class="more-authors" title="click to view 10 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '10 more authors' ? 'Anna Cai, Ritam Dutt, Amey Hengle, Anubha Kabra, Atharva Kulkarni, Abhishek Vijayakumar, Haofei Yu, Hinrich Schuetze, Kemal Oflazer, David Mortensen' : '10 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">10 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, Dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Large language models (LLMs) have recently reached an impressive level of linguistic capability, prompting comparisons with human language skills. However, there have been relatively few systematic inquiries into the linguistic capabilities of the latest generation of LLMs, and those studies that do exist (i) ignore the remarkable ability of humans to generalize, (ii) focus only on English, and (iii) investigate syntax or semantics and overlook other capabilities that lie at the heart of human language, like morphology. Here, we close these gaps by conducting the first rigorous analysis of the morphological capabilities of ChatGPT in four typologically varied languages (specifically, English, German, Tamil, and Turkish). We apply a version of Berko’s (1958) wug test to ChatGPT, using novel, uncontaminated datasets for the four examined languages. We find that ChatGPT massively underperforms purpose-built systems, particularly in English. Overall, our results—through the lens of morphology—cast a new light on the linguistic capabilities of ChatGPT, suggesting that claims of human-like language skills are premature and misleading.</p> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 ChangeLing Lab. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"David Mortensen's publications including all publications with other members of ChangeLing Lab.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"Ongoing ChangeLing Lab Projects",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-people",title:"people",description:"Members and retroactive alumni of ChangLing Lab",section:"Navigation",handler:()=>{window.location.href="/people/"}},{id:"post-information-and-comparative-reconstruction",title:"Information and Comparative Reconstruction",description:"Informal information-theoretic framing of the comparative method in historical linguistics",section:"Posts",handler:()=>{window.location.href="/blog/2024/hl_and_information/"}},{id:"post-on-our-acl-best-paper-award-paper",title:"On our ACL Best Paper Award Paper",description:"a short philosophical discursion",section:"Posts",handler:()=>{window.location.href="/blog/2024/best_paper/"}},{id:"post-is-acl-an-ai-or-nlp-or-cl-conference",title:"Is ACL an AI (or NLP or CL) Conference?",description:"Ruminations on Emily Bender's Presidential Address at ACL2024",section:"Posts",handler:()=>{window.location.href="/blog/2024/cl_in_acl/"}},{id:"post-why-does-diachronic-linguistics-matter",title:"Why does diachronic linguistics matter?",description:"a short philosophical discursion",section:"Posts",handler:()=>{window.location.href="/blog/2024/why-diachronic-linguistics/"}},{id:"news-sparkles-changeling-lab-is-officially-born-sparkles-though-it-has-long-existed-in-fact",title:'<img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> ChangeLing Lab is officially born! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> (though it has long existed in...',description:"",section:"News"},{id:"news-congratulations-to-liang-leon-lu-for-winning-the-acl2024-best-paper-award-non-publicized-with-his-paper-self-supervised-neural-protolanguage-reconstruction-joint-work-with-peirong-xie-and-david-mortensen",title:"Congratulations to Liang (Leon) Lu for winning the ACL2024 Best Paper Award (Non-Publicized)...",description:"",section:"News"},{id:"news-david-mortensen-gave-a-clsp-seminar-at-johns-hopkins-university",title:"David Mortensen gave a CLSP Seminar at Johns Hopkins University.",description:"",section:"News"},{id:"news-congratulations-to-kalvin-chang-and-david-mortensen-for-winning-an-honorable-mention-best-paper-award-at-the-interspeech-2024-responsible-speech-foundation-models-special-session-with-their-paper-self-supervised-speech-representations-still-struggle-with-african-american-vernacular-english-joint-work-with-yi-hui-chou-hsuan-ming-chen-jiatong-shi-nicole-holliday-and-odette-scharenborg",title:"Congratulations to Kalvin Chang and David Mortensen for winning an Honorable Mention, Best...",description:"",section:"News"},{id:"news-david-mortensen-will-give-a-talk-as-part-of-the-university-of-pittsburgh-colloquium-series",title:"David Mortensen will give a talk as part of the University of Pittsburgh...",description:"",section:"News"},{id:"news-changeling-lab-member-brendon-boldt-will-present-two-papers-in-the-main-session-of-emnlp-2025-in-suzhou-morpheme-induction-for-emergent-language-and-searching-for-the-most-human-like-emergent-language",title:"Changeling Lab member Brendon Boldt will present two papers in the main session...",description:"",section:"News"},{id:"projects-systematic-relationships-for-improved-asr",title:"Systematic Relationships for Improved ASR",description:"Better ASR for low resource varieties",section:"Projects",handler:()=>{window.location.href="/projects/10_systematic/"}},{id:"projects-universal-phone-recognition",title:"Universal Phone Recognition",description:"Recognizing phonetic units in a language-neural fashion",section:"Projects",handler:()=>{window.location.href="/projects/10_universal/"}},{id:"projects-implicit-and-explicit-reasoning-in-llms",title:"Implicit and Explicit Reasoning in LLMs",description:"Do LLMs introspect?",section:"Projects",handler:()=>{window.location.href="/projects/11_blocking/"}},{id:"projects-fbcc-benchmark",title:"FBCC Benchmark",description:"Evaluating the ability of code language models to generalize and plan based on examples",section:"Projects",handler:()=>{window.location.href="/projects/12_benchmark/"}},{id:"projects-automating-comparative-reconstruction",title:"Automating Comparative Reconstruction",description:"Work on developing models that reconstruct protolanguages based on collections of cognate sets",section:"Projects",handler:()=>{window.location.href="/projects/1_automating/"}},{id:"projects-historical-linguistics-as-code-generation",title:"Historical Linguistics as Code Generation",description:"Modeling phonological reconstruction as a code generation problem using LLMs",section:"Projects",handler:()=>{window.location.href="/projects/2_codegen/"}},{id:"projects-emergent-language-corpus-collection",title:"Emergent Language Corpus Collection",description:"Building a collection of corpora from emergent communication systems",section:"Projects",handler:()=>{window.location.href="/projects/3_elcc/"}},{id:"projects-wuggpt",title:"WugGPT",description:"Evaluating the morphological capabilities of Large Language Models",section:"Projects",handler:()=>{window.location.href="/projects/4_wuggpt/"}},{id:"projects-xferbench",title:"XferBench",description:"Evaluating Emergent Communication Systems with Downstream Tasks",section:"Projects",handler:()=>{window.location.href="/projects/5_xferbench/"}},{id:"projects-lexical-change",title:"Lexical Change",description:"Corpus approaches to changes in lexicons",section:"Projects",handler:()=>{window.location.href="/projects/6_lexical_change/"}},{id:"projects-atypical-speech-assessment",title:"Atypical Speech Assessment",description:"Assessing the degree to which speech is atypical",section:"Projects",handler:()=>{window.location.href="/projects/7_evaluating/"}},{id:"projects-phonological-representations-for-nlp",title:"Phonological Representations for NLP",description:"Leveraging phonological representations for NLP tasks",section:"Projects",handler:()=>{window.location.href="/projects/8_phonology_for_nlp/"}},{id:"projects-blocking-in-llms",title:"Blocking in LLMs",description:"Do LLMs know the badness of badity?",section:"Projects",handler:()=>{window.location.href="/projects/9_implicit_explicit/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%64%6D%6F%72%74%65%6E%73@%63%73.%63%6D%75.%65%64%75","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0002-3927-6851","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=2iS5aeoAAAAJ&hl","_blank")}},{id:"socials-semantic-scholar",title:"Semantic Scholar",section:"Socials",handler:()=>{window.open("https://www.semanticscholar.org/author/3407646","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/changelinglab","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/dmort27","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>